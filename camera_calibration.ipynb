{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Camera Calibration"]},{"cell_type":"markdown","metadata":{},"source":["## EDITED FROM KAGGLE by safal"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T11:08:43.470037Z","iopub.status.busy":"2024-04-17T11:08:43.469619Z","iopub.status.idle":"2024-04-17T11:08:43.557666Z","shell.execute_reply":"2024-04-17T11:08:43.556779Z","shell.execute_reply.started":"2024-04-17T11:08:43.470006Z"},"trusted":true},"outputs":[],"source":["import git\n","import shutil\n","def clone():\n","    # URL of the repository to clone\n","    \n","    repo_url = 'https://github.com/markakash/BigTree.git'\n","\n","    # The path where the repository will be cloned\n","    clone_path = '/kaggle/working/BigTree'\n","\n","    # Name of the branch you want to clone\n","    branch_name = 'kaggle'\n","\n","    # Cloning the specific branch\n","    git.Repo.clone_from(repo_url, clone_path, branch=branch_name)"]},{"cell_type":"markdown","metadata":{},"source":["### Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T11:08:47.207386Z","iopub.status.busy":"2024-04-17T11:08:47.207019Z","iopub.status.idle":"2024-04-17T11:08:47.212223Z","shell.execute_reply":"2024-04-17T11:08:47.211135Z","shell.execute_reply.started":"2024-04-17T11:08:47.207357Z"},"trusted":true},"outputs":[],"source":["VIDEO_CALIBRATION_PATH = \"kaggle/input/video/calibration.MP4\"\n","EXTRACT_FRAMES = True\n","CHECKERBOARD_SIZE = (6, 8)"]},{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T11:09:23.938527Z","iopub.status.busy":"2024-04-17T11:09:23.938111Z","iopub.status.idle":"2024-04-17T11:09:39.653287Z","shell.execute_reply":"2024-04-17T11:09:39.651845Z","shell.execute_reply.started":"2024-04-17T11:09:23.938483Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import glob\n","from termcolor import colored\n","import imageio\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T11:10:58.254908Z","iopub.status.busy":"2024-04-17T11:10:58.254444Z","iopub.status.idle":"2024-04-17T11:24:45.222054Z","shell.execute_reply":"2024-04-17T11:24:45.214666Z","shell.execute_reply.started":"2024-04-17T11:10:58.254869Z"},"trusted":true},"outputs":[],"source":["if EXTRACT_FRAMES:\n","    reader = imageio.get_reader(VIDEO_CALIBRATION_PATH)\n","\n","    try:\n","        for i, frame in enumerate(reader):\n","            cv2.imwrite(f'kaggle/working/calibration_frames/frame_{i}.png', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n","            print(f'Read frame: {i}', end='\\r')\n","    except Exception as e:\n","        print(f'An error occurred: {e}')\n","    finally:\n","        reader.close()"]},{"cell_type":"markdown","metadata":{},"source":["### Calibration matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Init our checkerboard in 3 dimensions\n","# checkerboard_world_space = np.zeros((CHECKERBOARD_SIZE[0]*CHECKERBOARD_SIZE[1],3), np.float32)\n","# checkerboard_world_space[:,:2] = np.mgrid[0:CHECKERBOARD_SIZE[0],0:CHECKERBOARD_SIZE[1]].T.reshape(-1,2)\n","\n","# objpoints = [] # 3D points in real world space\n","# imgpoints = [] # 2D points in image plane\n","\n","# for file in glob.glob('assets/calibration_frames/*.png'):\n","#     img = cv2.imread(file)\n","#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","#     # Find the chess board corners, thank you cv2 for providing such a useful function\n","#     ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD_SIZE, None)\n","\n","#     if ret == True:\n","#         objpoints.append(checkerboard_world_space)\n","#         imgpoints.append(corners)\n","\n","# # Calibrate camera\n","# ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n","\n","# print(colored(\"Camera matrix:\\n\\n\", \"green\"), mtx, \"\\n\")\n","# print(colored(\"Distortion coefficients:\\n\\n\", \"green\"), dist)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T10:51:51.477737Z","iopub.status.busy":"2024-04-17T10:51:51.476938Z","iopub.status.idle":"2024-04-17T10:51:51.491688Z","shell.execute_reply":"2024-04-17T10:51:51.490670Z","shell.execute_reply.started":"2024-04-17T10:51:51.477701Z"},"trusted":true},"outputs":[],"source":["def calibrate_camera_with_subsets(subset_size=100, n_experiments=20):\n","    files = glob.glob('kaggle/working/calibration_frames/*.png')\n","    np.random.seed(42)\n","        \n","    camera_matrices = []\n","    distortion_coefficients = []\n","    \n","    best_mtx = None\n","    best_dist = None\n","    lowest_error = np.inf\n","    \n","    for _ in range(n_experiments):\n","        random_selected_files = np.random.choice(files, size=subset_size, replace=False)\n","        \n","        objpoints = [] # 3D points in real world space\n","        imgpoints = [] # 2D points in image plane\n","        \n","        checkerboard_world_space = np.zeros((CHECKERBOARD_SIZE[0]*CHECKERBOARD_SIZE[1], 3), np.float32)\n","        checkerboard_world_space[:, :2] = np.mgrid[0:CHECKERBOARD_SIZE[0], 0:CHECKERBOARD_SIZE[1]].T.reshape(-1, 2)\n","        \n","        for file in random_selected_files:\n","            img = cv2.imread(file)\n","            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","            \n","            # Find the chess board corners\n","            ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD_SIZE, None)\n","            \n","            # If found, add object points, image points\n","            if ret == True:\n","                objpoints.append(checkerboard_world_space)\n","                imgpoints.append(corners)\n","        \n","        # Calibrate camera\n","        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n","        \n","        # Store calibration parameters\n","        if ret:\n","            camera_matrices.append(mtx)\n","            distortion_coefficients.append(dist)\n","            \n","            # Calculate re-projection error\n","            mean_error = 0\n","            for i in range(len(objpoints)):\n","                imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n","                error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n","                mean_error += error\n","            \n","            if(mean_error < lowest_error):\n","                lowest_error = mean_error\n","                best_mtx = mtx\n","                best_dist = dist\n","    \n","    # Numpy is more efficient...\n","    camera_matrices = np.array(camera_matrices)\n","    distortion_coefficients = np.array(distortion_coefficients)\n","    \n","    # Compute standard deviation\n","    camera_matrices_std = np.std(camera_matrices, axis=0)\n","    distortion_coefficients_std = np.std(distortion_coefficients, axis=0)\n","    \n","    return best_mtx, best_dist, camera_matrices_std, distortion_coefficients_std"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T10:51:57.805593Z","iopub.status.busy":"2024-04-17T10:51:57.804914Z","iopub.status.idle":"2024-04-17T10:59:21.265787Z","shell.execute_reply":"2024-04-17T10:59:21.264601Z","shell.execute_reply.started":"2024-04-17T10:51:57.805562Z"},"trusted":true},"outputs":[],"source":["best_mtx, best_dist, camera_matrices_std, distortion_coefficients_std = calibrate_camera_with_subsets()\n","print(\"\\nStandard deviation of camera matrices:\\n\", camera_matrices_std)\n","print(\"\\nStandard deviation of distortion coefficients:\\n\", distortion_coefficients_std)\n","print(\"\\nBest camera matrix:\\n\", best_mtx)\n","print(\"\\nBest distortion coefficients:\\n\", best_dist)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# \n","def match_frames(img1, img2):\n","    # Create SIFT detector\n","    sift = cv2.SIFT_create()\n","\n","    # Detect keypoints and compute descriptors\n","    keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n","    keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n","\n","    # Create BFMatcher object with default params\n","    bf = cv2.BFMatcher()\n","\n","    # Match descriptors\n","    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n","\n","    # Apply ratio test to find good matches\n","    good_matches = []\n","    pts1 = []\n","    pts2 = []\n","\n","    for m, n in matches:\n","        if m.distance < 0.75 * n.distance:  # only accept matchs that are significantly better than the second best match\n","            good_matches.append(m)\n","            pts1.append(keypoints1[m.queryIdx].pt)\n","            pts2.append(keypoints2[m.trainIdx].pt)\n","\n","    pts1 = np.float32(pts1)\n","    pts2 = np.float32(pts2)\n","\n","    # Compute the fundamental matrix\n","    fundamental_matrix, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)\n","\n","    return pts1, pts2, fundamental_matrix\n","\n","def compute_essential_matrix(fundamental_matrix, calibration_matrix):\n","    E = calibration_matrix.T @ fundamental_matrix @ calibration_matrix\n","    return E"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# This is an implementation of the 5-point algorithm for computing the essential matrix from a set of 5 correspondences.\n","# This isn't being used. We are using the match_frame one.\n","def match_sift_descriptors(img1, img2, drawepilines=False, threshold=0.75):\n","    \"\"\"Matches SIFT descriptors between two images and optionally draws epilines.\"\"\"\n","    sift = cv2.SIFT_create()\n","    kp1, des1 = sift.detectAndCompute(img1, None)\n","    kp2, des2 = sift.detectAndCompute(img2, None)\n","    FLANN_INDEX_KDTREE = 1\n","    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n","    search_params = dict(checks = 50)\n","    flann = cv2.FlannBasedMatcher(index_params, search_params)\n","    matches = flann.knnMatch(des1, des2, k=2)\n","    good_matches = []\n","    pts1 = []\n","    pts2 = []\n","    for m, n in matches:\n","        if m.distance < threshold * n.distance:\n","            good_matches.append(m)\n","            pts2.append(kp2[m.trainIdx].pt)\n","            pts1.append(kp1[m.queryIdx].pt)\n","    pts1 = np.int32(pts1)\n","    pts2 = np.int32(pts2)\n","    if drawepilines:\n","        F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_LMEDS)\n","        pts1 = pts1[mask.ravel() == 1]\n","        pts2 = pts2[mask.ravel() == 1]\n","        lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n","        lines1 = lines1.reshape(-1, 3)\n","        img1_with_lines, img2_with_lines = draw_epilines(img1, img2, lines1, pts1, pts2)\n","        return pts1, pts2, F, img1_with_lines, img2_with_lines\n","    else:\n","        img_matches = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","        return img_matches"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m current_frame_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(current_frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Compute the fundamental matrix\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m pts1, pts2, fundamental_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mmatch_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_frame_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_frame_gray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Compute the essential matrix\u001b[39;00m\n\u001b[1;32m     20\u001b[0m essential_matrix \u001b[38;5;241m=\u001b[39m compute_essential_matrix(fundamental_matrix, calibration_matrix)\n","Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mmatch_frames\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m     10\u001b[0m bf \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mBFMatcher()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Match descriptors\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknnMatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptors1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptors2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Apply ratio test to find good matches\u001b[39;00m\n\u001b[1;32m     16\u001b[0m good_matches \u001b[38;5;241m=\u001b[39m []\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Setup video capture\n","cap = cv2.VideoCapture('kaggle/input/video/eastbound_20240319_short_20fps_compressed.MP4')\n","calibration_matrix = best_mtx\n","\n","results = {}\n","frame_index = 0\n","ret, previous_frame = cap.read()\n","previous_frame_gray = cv2.cvtColor(previous_frame, cv2.COLOR_BGR2GRAY)\n","\n","while True:\n","    ret, current_frame = cap.read()\n","    if not ret:\n","        break\n","    current_frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n","\n","    # Compute the fundamental matrix\n","    pts1, pts2, fundamental_matrix = match_frames(previous_frame_gray, current_frame_gray)\n","\n","    # Compute the essential matrix\n","    essential_matrix = compute_essential_matrix(fundamental_matrix, calibration_matrix)\n","\n","    # Decompose the essential matrix\n","    R1, R2, t = cv2.decomposeEssentialMat(essential_matrix)\n","\n","    # Store results in the dictionary\n","    results[f\"Frame {frame_index}-{frame_index+1}\"] = {\n","        \"Fundamental Matrix\": fundamental_matrix,\n","        \"Essential Matrix\": essential_matrix,\n","        \"Rotation Matrix 1\": R1,\n","        \"Rotation Matrix 2\": R2,\n","        \"Translation Vector\": t.ravel().tolist()\n","    }\n","\n","    # Update the previous frame\n","    previous_frame_gray = current_frame_gray\n","    frame_index += 1\n","\n","cap.release()\n","\n","# Save results to a JSON file\n","with open('output_matrices.json', 'w') as file:\n","    json.dump(results, file, indent=4)"]},{"cell_type":"markdown","metadata":{},"source":["## Results\n","```py\n","Standard deviation of camera matrices:\n"," [[3.70849068 0.         5.82549989]\n"," [0.         2.98369589 9.05924656]\n"," [0.         0.         0.        ]]\n","\n","Standard deviation of distortion coefficients:\n"," [[0.00296308 0.00773438 0.00029421 0.00040361 0.00619906]]\n","\n","Best camera matrix:\n"," [[1.41527706e+03 0.00000000e+00 1.32534026e+03]\n"," [0.00000000e+00 1.42789878e+03 8.00498436e+02]\n"," [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n","\n","Best distortion coefficients:\n"," [[-0.28111115  0.14996815  0.00110429  0.00084166 -0.05461088]]\n"," ```"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T11:03:27.751497Z","iopub.status.busy":"2024-04-17T11:03:27.750720Z","iopub.status.idle":"2024-04-17T11:03:30.527215Z","shell.execute_reply":"2024-04-17T11:03:30.525783Z","shell.execute_reply.started":"2024-04-17T11:03:27.751468Z"},"trusted":true},"outputs":[],"source":["frame_test = cv2.imread('/kaggle/working/calibration_frames/frame_555.png')\n","\n","# Undistort image\n","undistorted_img = cv2.undistort(frame_test, best_mtx, best_dist, None, best_mtx)\n","\n","fig, axs = plt.subplots(1, 2, figsize=(30, 20))\n","axs[0].imshow(frame_test)\n","axs[0].set_title('Original Image')\n","axs[0].axis('off')\n","\n","axs[1].imshow(undistorted_img)\n","axs[1].set_title('Undistorted Image')\n","axs[1].axis('off')\n","\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
